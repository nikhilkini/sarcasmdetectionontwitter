{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import operator\n",
    "import os\n",
    "import nltk\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.util import ngrams\n",
    "import random\n",
    "import re\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "riloff_eval_dataset = pickle.load(open('march27/riloff-tokenized-and-tagged.pkl','rb'))\n",
    "for i in range(10):\n",
    "    random.shuffle(riloff_eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_set_x = [tweet['text'].lower().replace('#sarcasm','').replace('#sarcastic','') for tweet in riloff_eval_dataset[:200]]\n",
    "train_set_y = [tweet['label'] for tweet in riloff_eval_dataset[:200]]\n",
    "test_set_x =  [tweet['text'].lower().replace('#sarcasm','').replace('#sarcastic','') for tweet in riloff_eval_dataset[200:]]\n",
    "test_set_y = [tweet['label'] for tweet in riloff_eval_dataset[200:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set_x_sklearn = [' '.join(tweet['tokens']).lower().replace('#sarcasm','').replace('#sarcastic','') for tweet in riloff_eval_dataset[:200]]\n",
    "test_set_x_sklearn =  [' '.join(tweet['tokens']).lower().replace('#sarcasm','').replace('#sarcastic','') for tweet in riloff_eval_dataset[200:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = ['NOT_SARCASM','SARCASM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.78      0.99      0.88      1498\n",
      "    SARCASM       0.53      0.04      0.07       426\n",
      "\n",
      "avg / total       0.73      0.78      0.70      1924\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.80      0.86      0.83      1498\n",
      "    SARCASM       0.35      0.26      0.30       426\n",
      "\n",
      "avg / total       0.70      0.73      0.71      1924\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.78      1.00      0.88      1498\n",
      "    SARCASM       0.00      0.00      0.00       426\n",
      "\n",
      "avg / total       0.61      0.78      0.68      1924\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.80      0.95      0.87      1498\n",
      "    SARCASM       0.47      0.15      0.22       426\n",
      "\n",
      "avg / total       0.72      0.77      0.72      1924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "If documents are pre-tokenized by an external package, \n",
    "then store them in files (or strings) with the tokens \n",
    "separated by whitespace and pass analyzer=str.split\n",
    "(from http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)\n",
    "'''\n",
    "\n",
    "vect = CountVectorizer(analyzer=str.split)\n",
    "clf = MultinomialNB()\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x_sklearn, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x_sklearn)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "vect = CountVectorizer(analyzer=str.split)\n",
    "clf =  SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x_sklearn, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x_sklearn)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "vect = CountVectorizer(analyzer=str.split)\n",
    "clf = MultinomialNB()\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x_sklearn, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x_sklearn)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "vect = CountVectorizer(analyzer=str.split)\n",
    "clf =  SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x_sklearn, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x_sklearn)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.78      0.99      0.87      1498\n",
      "    SARCASM       0.36      0.03      0.05       426\n",
      "\n",
      "avg / total       0.69      0.77      0.69      1924\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.79      0.93      0.86      1498\n",
      "    SARCASM       0.37      0.15      0.21       426\n",
      "\n",
      "avg / total       0.70      0.76      0.71      1924\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.78      1.00      0.88      1498\n",
      "    SARCASM       0.00      0.00      0.00       426\n",
      "\n",
      "avg / total       0.61      0.78      0.68      1924\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.80      0.94      0.87      1498\n",
      "    SARCASM       0.47      0.18      0.26       426\n",
      "\n",
      "avg / total       0.73      0.77      0.73      1924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(analyzer=str.split)\n",
    "clf = MultinomialNB()\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "vect = CountVectorizer(analyzer=str.split)\n",
    "clf =  SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "vect = CountVectorizer(analyzer=str.split)\n",
    "clf = MultinomialNB()\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "vect = CountVectorizer(analyzer=str.split)\n",
    "clf =  SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.78      0.98      0.87      1498\n",
      "    SARCASM       0.48      0.05      0.09       426\n",
      "\n",
      "avg / total       0.72      0.78      0.70      1924\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.80      0.94      0.86      1498\n",
      "    SARCASM       0.41      0.16      0.23       426\n",
      "\n",
      "avg / total       0.71      0.76      0.72      1924\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.78      1.00      0.88      1498\n",
      "    SARCASM       0.00      0.00      0.00       426\n",
      "\n",
      "avg / total       0.61      0.78      0.68      1924\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.80      0.93      0.86      1498\n",
      "    SARCASM       0.44      0.19      0.26       426\n",
      "\n",
      "avg / total       0.72      0.77      0.73      1924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "clf = MultinomialNB()\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "vect = CountVectorizer()\n",
    "clf =  SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "vect = CountVectorizer()\n",
    "clf = MultinomialNB()\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "vect = CountVectorizer()\n",
    "clf =  SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(2))\n",
    "clf = MultinomialNB()\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "vect = CountVectorizer()\n",
    "clf =  SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "vect = CountVectorizer()\n",
    "clf = MultinomialNB()\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "vect = CountVectorizer()\n",
    "clf =  SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.78      0.99      0.88      1498\n",
      "    SARCASM       0.53      0.04      0.07       426\n",
      "\n",
      "avg / total       0.73      0.78      0.70      1924\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.80      0.86      0.83      1498\n",
      "    SARCASM       0.35      0.26      0.30       426\n",
      "\n",
      "avg / total       0.70      0.73      0.71      1924\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.78      1.00      0.88      1498\n",
      "    SARCASM       0.00      0.00      0.00       426\n",
      "\n",
      "avg / total       0.61      0.78      0.68      1924\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.80      0.95      0.87      1498\n",
      "    SARCASM       0.47      0.15      0.22       426\n",
      "\n",
      "avg / total       0.72      0.77      0.72      1924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(analyzer=str.split, ngram_range=(2,2))\n",
    "clf = MultinomialNB()\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x_sklearn, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x_sklearn)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "vect = CountVectorizer(analyzer=str.split, ngram_range=(2,2))\n",
    "clf =  SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x_sklearn, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x_sklearn)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "vect = CountVectorizer(analyzer=str.split, ngram_range=(2,2))\n",
    "clf = MultinomialNB()\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x_sklearn, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x_sklearn)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "vect = CountVectorizer(analyzer=str.split, ngram_range=(2,2))\n",
    "clf =  SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x_sklearn, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x_sklearn)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.79      0.98      0.88      1498\n",
      "    SARCASM       0.65      0.10      0.17       426\n",
      "\n",
      "avg / total       0.76      0.79      0.72      1924\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.80      0.98      0.88      1498\n",
      "    SARCASM       0.58      0.12      0.19       426\n",
      "\n",
      "avg / total       0.75      0.79      0.73      1924\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.78      1.00      0.88      1498\n",
      "    SARCASM       0.00      0.00      0.00       426\n",
      "\n",
      "avg / total       0.61      0.78      0.68      1924\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.79      0.98      0.87      1498\n",
      "    SARCASM       0.51      0.08      0.14       426\n",
      "\n",
      "avg / total       0.73      0.78      0.71      1924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(ngram_range=(2,2))\n",
    "clf = MultinomialNB()\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(2,2))\n",
    "clf =  SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(2,2))\n",
    "clf = MultinomialNB()\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(2,2))\n",
    "clf =  SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.80      0.95      0.87      1498\n",
      "    SARCASM       0.47      0.15      0.22       426\n",
      "\n",
      "avg / total       0.72      0.77      0.72      1924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(analyzer=str.split)\n",
    "clf =  SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x_sklearn, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x_sklearn)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(train_set_x_sklearn,train_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83999999999999997"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gs_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__alpha: 0.01\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(gs_clf.best_score_)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.855\n",
      "clf__alpha: 0.001\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (2, 2)\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "clf =  SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', clf)])\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-1, 1e-2, 1e-3, 1e-4),\n",
    "}\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(train_set_x,train_set_y)\n",
    "print(gs_clf.best_score_)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81\n",
      "clf__alpha: 0.001\n",
      "clf__loss: 'squared_hinge'\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 1)\n",
      "0.82\n",
      "clf__alpha: 0.0001\n",
      "clf__loss: 'log'\n",
      "tfidf__use_idf: False\n",
      "vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "for i in range(10):\n",
    "    random.shuffle(riloff_eval_dataset)\n",
    "\n",
    "train_set_x_sklearn = [' '.join(tweet['tokens']).lower().replace('#sarcasm','').replace('#sarcastic','') for tweet in riloff_eval_dataset[:200]]\n",
    "test_set_x_sklearn =  [' '.join(tweet['tokens']).lower().replace('#sarcasm','').replace('#sarcastic','') for tweet in riloff_eval_dataset[200:]]\n",
    "train_set_x = [tweet['text'].lower().replace('#sarcasm','').replace('#sarcastic','') for tweet in riloff_eval_dataset[:200]]\n",
    "test_set_x =  [tweet['text'].lower().replace('#sarcasm','').replace('#sarcastic','') for tweet in riloff_eval_dataset[200:]]\n",
    "\n",
    "train_set_y = [tweet['label'] for tweet in riloff_eval_dataset[:200]]\n",
    "test_set_y = [tweet['label'] for tweet in riloff_eval_dataset[200:]]\n",
    "'''\n",
    "\n",
    "vect = CountVectorizer()\n",
    "clf =  SGDClassifier(penalty='l2', n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', clf)])\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-1, 1e-2, 1e-3, 1e-4),\n",
    "              'clf__loss': ('hinge','squared_hinge','log')\n",
    "}\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1,cv=10)\n",
    "gs_clf = gs_clf.fit(train_set_x,train_set_y)\n",
    "print(gs_clf.best_score_)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))\n",
    "    \n",
    "vect = CountVectorizer(tokenizer=str.split)\n",
    "clf =  SGDClassifier(penalty='l2', n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', clf)])\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-1, 1e-2, 1e-3, 1e-4),\n",
    "              'clf__loss': ('hinge','squared_hinge','log')\n",
    "}\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1,cv=10)\n",
    "gs_clf = gs_clf.fit(train_set_x_sklearn,train_set_y)\n",
    "print(gs_clf.best_score_)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.82      0.86      0.84      1512\n",
      "    SARCASM       0.36      0.30      0.33       412\n",
      "\n",
      "avg / total       0.72      0.74      0.73      1924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "PREVIOUS BEST (with a different data set):\n",
    "vect = CountVectorizer(analyzer=str.split)\n",
    "clf =  SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x_sklearn, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x_sklearn)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "    \n",
    " precision    recall  f1-score   support\n",
    "\n",
    "NOT_SARCASM       0.80      0.86      0.83      1498\n",
    "    SARCASM       0.35      0.26      0.30       426\n",
    "\n",
    "avg / total       0.70      0.73      0.71      1924\n",
    "'''\n",
    "\n",
    "vect = CountVectorizer(tokenizer=str.split,ngram_range=(1,1))\n",
    "clf =  SGDClassifier(loss='log', penalty='l2', alpha=1e-4, n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x_sklearn, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x_sklearn)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "## THIS WAS CHOSEN OVER THE ONE BELOW, because of a healthier f1-score on SARCASM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83\n",
      "clf__alpha: 0.001\n",
      "clf__loss: 'hinge'\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 2)\n",
      "0.82\n",
      "clf__alpha: 0.01\n",
      "clf__loss: 'squared_hinge'\n",
      "tfidf__use_idf: False\n",
      "vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "for i in range(10):\n",
    "    random.shuffle(riloff_eval_dataset)\n",
    "\n",
    "train_set_x_sklearn = [' '.join(tweet['tokens']).lower().replace('#sarcasm','').replace('#sarcastic','') for tweet in riloff_eval_dataset[:200]]\n",
    "test_set_x_sklearn =  [' '.join(tweet['tokens']).lower().replace('#sarcasm','').replace('#sarcastic','') for tweet in riloff_eval_dataset[200:]]\n",
    "train_set_x = [tweet['text'].lower().replace('#sarcasm','').replace('#sarcastic','') for tweet in riloff_eval_dataset[:200]]\n",
    "test_set_x =  [tweet['text'].lower().replace('#sarcasm','').replace('#sarcastic','') for tweet in riloff_eval_dataset[200:]]\n",
    "\n",
    "train_set_y = [tweet['label'] for tweet in riloff_eval_dataset[:200]]\n",
    "test_set_y = [tweet['label'] for tweet in riloff_eval_dataset[200:]]\n",
    "'''\n",
    "\n",
    "vect = CountVectorizer()\n",
    "clf =  SGDClassifier(penalty='l2', n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', clf)])\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-1, 1e-2, 1e-3, 1e-4),\n",
    "              'clf__loss': ('hinge','squared_hinge','log')\n",
    "}\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1,cv=10)\n",
    "gs_clf = gs_clf.fit(train_set_x,train_set_y)\n",
    "print(gs_clf.best_score_)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))\n",
    "    \n",
    "vect = CountVectorizer(tokenizer=str.split)\n",
    "clf =  SGDClassifier(penalty='l2', n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', clf)])\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-1, 1e-2, 1e-3, 1e-4),\n",
    "              'clf__loss': ('hinge','squared_hinge','log')\n",
    "}\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1,cv=10)\n",
    "gs_clf = gs_clf.fit(train_set_x_sklearn,train_set_y)\n",
    "print(gs_clf.best_score_)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.79      1.00      0.88      1512\n",
      "    SARCASM       1.00      0.01      0.02       412\n",
      "\n",
      "avg / total       0.83      0.79      0.70      1924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2))\n",
    "clf =  SGDClassifier(loss='hinge', penalty='l2', alpha=1e-2, n_iter=5, random_state=42)\n",
    "text_clf = Pipeline([('vect', vect),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                     ('clf', clf)])\n",
    "_ = text_clf.fit(train_set_x, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x)\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_to_use = (train_set_x_sklearn,train_set_y,test_set_x_sklearn,test_set_y)\n",
    "pickle.dump(dataset_to_use,open('march27/dataset_used-includes_train_test_split.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
